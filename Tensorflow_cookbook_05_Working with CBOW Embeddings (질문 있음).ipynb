{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\snuist\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import string\n",
    "import requests\n",
    "import collections\n",
    "import io\n",
    "import tarfile\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "# Load text helpers\n",
    "import text_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder_name = 'temp'\n",
    "if not os.path.exists(data_folder_name):\n",
    "    os.makedirs(data_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "batch_size = 200            # Model Batch Size\n",
    "embedding_size = 50        # word embedding size\n",
    "vocabulary_size = 2000      # Maximum vocabulary size\n",
    "generations = 50000         # number of iterations for training.\n",
    "model_learning_rate = 0.05   # Learning rate\n",
    "\n",
    "num_sampled = int(batch_size/2) # Number of negative examples to sample.\n",
    "window_size = 3                 # How many words to consider left and right.\n",
    "\n",
    "# Add checkpoints to training\n",
    "save_embeddings_every = 5000\n",
    "print_valid_every = 5000\n",
    "print_loss_every = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 로딩 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Normalizing Text Data\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Declare stopwords\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "# test words. We are expecting synonyms to appear\n",
    "valid_words = ['love', 'hate', 'happy', 'sad', 'man', 'woman']\n",
    "# Later we will have to transform these into indices\n",
    "\n",
    "# Load the movie review data\n",
    "print(\"Loading Data\")\n",
    "texts, target = text_helpers.load_movie_data()  # target: 0(negative)/1(positive)\n",
    "\n",
    "# Normalize text\n",
    "print(\"Normalizing Text Data\")\n",
    "texts = text_helpers.normalize_text(texts, stops)\n",
    "\n",
    "# Texts must contain at least 3 words\n",
    "target = [target[ix] for ix, x in enumerate(texts) if len(x.split())>2] \n",
    "texts = [x for x in texts if len(x.split())>2] # 너무 짧은 글은 제외\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dictionary\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Dictionary\")\n",
    "word_dictionary = text_helpers.build_dictionary(texts, vocabulary_size)\n",
    "word_dictionary_rev = dict(zip(word_dictionary.values(), word_dictionary.keys()))\n",
    "text_data = text_helpers.text_to_numbers(texts, word_dictionary)\n",
    "\n",
    "# Get validation word keys\n",
    "valid_examples = [word_dictionary[x] for x in valid_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Model\")\n",
    "# Define embeddings\n",
    "embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "# NCE Loss\n",
    "nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size],\n",
    "                                             stddev=1.0/np.sqrt(embedding_size)))\n",
    "nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "# Create data/target placeholders\n",
    "x_inputs = tf.placeholder(tf.int32, shape=[batch_size,2*window_size])\n",
    "y_target = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "# Lookup the word embedding\n",
    "# Add together window embeddings:\n",
    "embed = tf.zeros([batch_size, embedding_size])\n",
    "for element in range(2*window_size):  # 문맥이 되는 단어들의 합을 사용하여 중심단어 추정\n",
    "    embed += tf.nn.embedding_lookup(embeddings, x_inputs[:, element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_weights,\n",
    "                                     biases=nce_biases,\n",
    "                                     labels=y_target,\n",
    "                                     inputs=embed,\n",
    "                                     num_sampled=num_sampled,\n",
    "                                     num_classes=vocabulary_size))\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=model_learning_rate).minimize(loss)\n",
    "\n",
    "# Cosine similarity between words\n",
    "norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "normalized_embeddings = embeddings / norm\n",
    "valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model saving operation\n",
    "saver = tf.train.Saver({\"embeddings\": embeddings})\n",
    "\n",
    "#Add variable initializer.\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문맥의 길이를 2*window_size + 1로 정했기 때문에 이것보다 짧은 문장은 training에 있어 의미가 없다. 따라서 문장 길이가 7보다 긴 것들만 필터링해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data = [x for x in text_data if len(x) >= (2*window_size+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레이닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Loss at step 1000 : 9.67491626739502\n",
      "Loss at step 2000 : 6.243814468383789\n",
      "Loss at step 3000 : 5.550598621368408\n",
      "Loss at step 4000 : 5.641958236694336\n",
      "Loss at step 5000 : 4.849673748016357\n",
      "Nearest to love: exercise, anything, situations, striking, charismatic,\n",
      "Nearest to hate: career, relatively, head, brought, trek,\n",
      "Nearest to happy: choose, birthday, morality, told, needs,\n",
      "Nearest to sad: ask, fashion, gets, many, disappointing,\n",
      "Nearest to man: watching, wonderful, ludicrous, fascinating, obvious,\n",
      "Nearest to woman: form, j, amateurish, imagination, tribute,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 6000 : 5.111420631408691\n",
      "Loss at step 7000 : 5.047321319580078\n",
      "Loss at step 8000 : 4.750290393829346\n",
      "Loss at step 9000 : 4.610687732696533\n",
      "Loss at step 10000 : 4.788057327270508\n",
      "Nearest to love: exercise, anything, situations, charismatic, striking,\n",
      "Nearest to hate: career, relatively, head, brought, designed,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, gets, fashion, many, problem,\n",
      "Nearest to man: wonderful, watching, obvious, ludicrous, fascinating,\n",
      "Nearest to woman: form, j, amateurish, imagination, lines,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 11000 : 4.825859069824219\n",
      "Loss at step 12000 : 4.527589797973633\n",
      "Loss at step 13000 : 4.713764190673828\n",
      "Loss at step 14000 : 4.684839725494385\n",
      "Loss at step 15000 : 4.594109058380127\n",
      "Nearest to love: situations, anything, exercise, charismatic, striking,\n",
      "Nearest to hate: career, head, relatively, brought, designed,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, gets, fashion, problem, many,\n",
      "Nearest to man: wonderful, obvious, directs, disappointing, harvard,\n",
      "Nearest to woman: j, form, amateurish, imagination, lines,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 16000 : 4.544894218444824\n",
      "Loss at step 17000 : 4.14098596572876\n",
      "Loss at step 18000 : 4.400602340698242\n",
      "Loss at step 19000 : 4.10105562210083\n",
      "Loss at step 20000 : 4.085442543029785\n",
      "Nearest to love: situations, anything, exercise, charismatic, striking,\n",
      "Nearest to hate: career, head, relatively, brought, designed,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, gets, problem, many,\n",
      "Nearest to man: wonderful, directs, obvious, harvard, disappointing,\n",
      "Nearest to woman: j, form, amateurish, imagination, lines,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 21000 : 4.364433765411377\n",
      "Loss at step 22000 : 4.183600425720215\n",
      "Loss at step 23000 : 4.317311763763428\n",
      "Loss at step 24000 : 4.161993026733398\n",
      "Loss at step 25000 : 4.003443717956543\n",
      "Nearest to love: situations, anything, charismatic, exercise, striking,\n",
      "Nearest to hate: career, head, relatively, brought, designed,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, gets, problem, many,\n",
      "Nearest to man: wonderful, directs, harvard, obvious, sound,\n",
      "Nearest to woman: j, form, amateurish, lines, imagination,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 26000 : 4.191041946411133\n",
      "Loss at step 27000 : 3.915449857711792\n",
      "Loss at step 28000 : 4.213561058044434\n",
      "Loss at step 29000 : 4.061770439147949\n",
      "Loss at step 30000 : 3.817517042160034\n",
      "Nearest to love: situations, anything, charismatic, exercise, striking,\n",
      "Nearest to hate: career, head, relatively, brought, designed,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, problem, gets, die,\n",
      "Nearest to man: wonderful, directs, harvard, sound, insights,\n",
      "Nearest to woman: j, form, amateurish, lines, imagination,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 31000 : 4.236146450042725\n",
      "Loss at step 32000 : 3.888152837753296\n",
      "Loss at step 33000 : 4.168288230895996\n",
      "Loss at step 34000 : 4.097410678863525\n",
      "Loss at step 35000 : 3.9661104679107666\n",
      "Nearest to love: situations, charismatic, anything, striking, exercise,\n",
      "Nearest to hate: career, head, relatively, brought, place,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, problem, gets, die,\n",
      "Nearest to man: wonderful, directs, harvard, insights, sound,\n",
      "Nearest to woman: j, form, amateurish, lines, imagination,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 36000 : 4.055755615234375\n",
      "Loss at step 37000 : 3.9758028984069824\n",
      "Loss at step 38000 : 3.8035848140716553\n",
      "Loss at step 39000 : 4.166144847869873\n",
      "Loss at step 40000 : 3.903984785079956\n",
      "Nearest to love: situations, charismatic, anything, striking, exercise,\n",
      "Nearest to hate: career, head, relatively, brought, place,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, problem, gets, die,\n",
      "Nearest to man: wonderful, directs, harvard, insights, sound,\n",
      "Nearest to woman: j, form, amateurish, lines, imagination,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 41000 : 3.9693665504455566\n",
      "Loss at step 42000 : 3.6561009883880615\n",
      "Loss at step 43000 : 3.894360065460205\n",
      "Loss at step 44000 : 3.926947832107544\n",
      "Loss at step 45000 : 3.992842674255371\n",
      "Nearest to love: situations, charismatic, anything, striking, thin,\n",
      "Nearest to hate: career, head, relatively, brought, place,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, problem, die, gets,\n",
      "Nearest to man: wonderful, directs, insights, harvard, sound,\n",
      "Nearest to woman: j, form, amateurish, lines, season,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n",
      "Loss at step 46000 : 3.8105127811431885\n",
      "Loss at step 47000 : 3.901858329772949\n",
      "Loss at step 48000 : 4.038485527038574\n",
      "Loss at step 49000 : 3.9385616779327393\n",
      "Loss at step 50000 : 3.6136343479156494\n",
      "Nearest to love: situations, charismatic, anything, striking, hugh,\n",
      "Nearest to hate: career, head, relatively, place, brought,\n",
      "Nearest to happy: choose, birthday, told, morality, needs,\n",
      "Nearest to sad: ask, fashion, problem, die, gets,\n",
      "Nearest to man: wonderful, directs, insights, harvard, sound,\n",
      "Nearest to woman: j, form, amateurish, lines, season,\n",
      "Model saved in file: C:\\Users\\snuist\\Dlearning\\NLP\\Tensorflow cookbook\\temp\\cbow_movie_embeddings.ckpt\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training\")\n",
    "loss_vec = []\n",
    "loss_x_vec = []\n",
    "for i in range(generations):\n",
    "    batch_inputs, batch_labels = text_helpers.generate_batch_data(text_data, batch_size,\n",
    "                                                                 window_size, method='cbow')\n",
    "    feed_dict = {x_inputs: batch_inputs, y_target: batch_labels}\n",
    "    \n",
    "    # Run the train step\n",
    "    sess.run(optimizer, feed_dict=feed_dict)\n",
    "    \n",
    "    # Return the loss\n",
    "    if (i+1)% print_loss_every==0:\n",
    "        loss_val = sess.run(loss, feed_dict=feed_dict)\n",
    "        loss_vec.append(loss_val)\n",
    "        loss_x_vec.append(i+1)\n",
    "        print('Loss at step {} : {}'.format(i+1, loss_val))\n",
    "        \n",
    "    # Validation: Print some random words and top 5 related words\n",
    "    if (i+1) % print_valid_every == 0:\n",
    "        sim = sess.run(similarity, feed_dict=feed_dict)\n",
    "        for j in range(len(valid_words)):\n",
    "            valid_word = word_dictionary_rev[valid_examples[j]]\n",
    "            top_k = 5\n",
    "            nearest = (-sim[j,:]).argsort()[1:top_k+1]\n",
    "            log_str = \"Nearest to {}:\".format(valid_word)\n",
    "            for k in range(top_k):\n",
    "                close_word = word_dictionary_rev[nearest[k]]\n",
    "                log_str = '{} {},'.format(log_str, close_word)\n",
    "            print(log_str)\n",
    "            \n",
    "    # Save dictionary + embeddings\n",
    "    if (i+1) % save_embeddings_every ==0:\n",
    "        with open(os.path.join(data_folder_name, 'movie_vocab.pkl'), 'wb') as f:\n",
    "            pickle.dump(word_dictionary, f)\n",
    "        \n",
    "        # Save embeddings\n",
    "        model_checkpoint_path = os.path.join(os.getcwd(),data_folder_name, 'cbow_movie_embeddings.ckpt')\n",
    "        save_path = saver.save(sess, model_checkpoint_path)\n",
    "        print('Model saved in file: {}'.format(save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VFX+PvDnk56QQgcRgViIFKmR\nBSRRISKLgBUVLPBFV37I6hdF/drWhrpWVBRXcVFcAUVdUVGpuhSFBUNHI4LSO0oVCCnP74+5CRPI\nTCZlMsnM83695sXk3nPvOWcyPLlz7txzjSRERCT4hQW6ASIiUjkU+CIiIUKBLyISIhT4IiIhQoEv\nIhIiFPgiIiFCgS8emVm4mR02syYVWVaCh5ldZGY/BLod4hsFfhBxArfgkW9mR91+vqG0+yOZRzKe\n5OaKLFtaZvakmU2o6P1WBWYWZWaPmdnPZvaHmW01sy/NLCPQbTuZmUWYGc2sWcEyknNJtgpcq6Q0\nIgLdAKk4JOMLnpvZRgC3kpzjqbyZRZDMrYy2hbriXmszMwCfAqgL4EYAKwAYgO4ALgPg8XdXWW2U\n4KIj/BDiHClPMbP3zewQgBvNrIuZ/dfM9pvZDjMbY2aRTvkiR3RmNtFZP93MDpnZIjNLLm1ZZ/2f\nnaPaA2b2qpl9Z2aDy9CnVmY2z2n/ajO7zG1dHzPLcurfamZ3Ocvrm9lXzja/m9l8D/su6NMdZrbB\nzPaa2TNmFuZW5lYz+8nM9jl9PeOkbW83s/UAfiqmiksBXAjgcpJLSB4nmU1yOsm73OpobGZTzWyP\n047hbuuedH6fE51+rjGzDqXY1uf3A4CC1+kH51Pj1WaW4Rxc+PL78PqekEpAUo8gfADYCCDjpGVP\nAjgOoC9cf+xjAZwP4E9wfdo7E8DPAP7qlI8AQADNnJ8nAtgLIBVAJIApACaWoWx9AIcAXO6suxtA\nDoDBHvryJIAJxSyPArABwH3OfjIAHAZwtrN+D4CuzvPaADo4z58H8JqzTRSACz3UW9CnOQBqAWgG\nYH1BOwFcA2AtgBSn7GMAFpy07Qxn29hi9v8CgDkl/B7D4Tryf9Bp69nO77aH22tzFK4/HuFO374t\nxbZlfj84yzIAbPTx9+HxPaFH5Tx0hB96viU5jWQ+yaMkvye5mGQuyV8BjIPrqNOTj0lmkswBMAlA\nuzKU7QNgBcnPnHUvwRUEpXUBXCHzPMkcuoavpgO43lmfA6ClmSWQ/J3kMrfljQA0oeuoel4J9TxD\nch/JjQDGABjgLB8K4GmSa+kaCnkSQCczO91t26edbY8Ws9+6AHYW/OB88tjvfOo57CzuDCCR5NNO\nW9cDGO/WRwCYR3ImyTwA7+HE6+zLtuV9P7gr6fcBlO79IxVMgR96trj/YGbnOicJd5rZQQBPwBVE\nnux0e34EQLyngl7KNnJvB0kC2OpD20/WCMBmZ/sCmwAUBO6VAPoB2Gxmc83sT87yZ5xyX5vZL2Z2\nbwn1uL9mm5x6AaApgLFOSO+H649WPoDGHrY92W8ATiv4geRukjXhOsKOcaujSUEdTj33AWjotp+T\nX+capdi2vO8HdyX9Poprq7f3j1QwBX7oOXl61DcBrIHrY3cigEfgOnHoTzvgFopmZigaCr7aDuAM\nZ/sCTQBsAwDnSLUfXENIXwD4wFl+kORdJJsBuALA/5mZt6PYM07a/3bn+RYAt5Cs6faIJbnYrby3\n6Wi/BtDZzBp5KbMFwLqT6kgg2dfLNqXZtjTvh5Km1vX6+5DAU+BLAoADAP4wsxZwDVP42xcAOphZ\nXzOLAPC/AOqVsE24mcW4PaIBLASQC2CkmUWaWXcAvQF8aGaxZjbQzBKd4YNDAPIAwKn3LCeYDjjL\n87zUfZ+Z1TTXNQZ3wjX2DABvAHjIed3glLmmFK/DdADfAvjUzDo5fYiEayimwCIAx81spNPvcDM7\nz8w6+rD/smzr8f3gDBn9BtfYfnE8/j58aKtUAgW+jAQwCK5AfBMnwsxvSO4CcB2A0XAFyFkAlgPI\n9rLZjXCdnCx4rCWZDdcJx8vhGk4ZA2AgyZ+dbQYB2OQMTdwC4CZneQqAb+A6ofgdgFdIfuul7mlw\nnfxcDmAqgAlOPz5y+vCRU8cquE6e+sQZ+rgcrhO7k+EK2g0ArgXQyymTC1dodoLrhOteuH5PiT7s\nvyzblvR+eBTAZGeI6KqT6ivp9yEBZkWH20Qqn5mFwzUccA3JBYFuTwHn00cOgGTnhK1ItaYjfAkI\nM+tlZknO0Mzf4BoKWBLgZokENQW+BEo3AL/C9dG/F4ArnCEBEfETDemIiIQIHeGLiISIKjV5Wt26\nddmsWbNAN0NEpNpYunTpXpIlfa0ZQBUL/GbNmiEzMzPQzRARqTbMbJOvZTWkIyISIhT4IiIhQoEv\nIhIiFPgiIiFCgS8iEiIU+CIiIUKBLyISIoIi8EeNGoWZM2cGuhkiIlVaUAT+888/r8AXESlBUAR+\nYmIiDhw4EOhmiIhUaUER+ElJSTh48GCgmyEiUqUFReAnJiYq8EVESqDAFxEJEUET+BrDFxHxLmgC\nX0f4IiLeBUXg66StiEjJgiLwExMTcejQIeTn5we6KSIiVVbQBD4AHD58OMAtERGpuoIq8HXiVkTE\ns6AKfI3ji4h4FhSBn5SUBECBLyLiTVAEvo7wRURKpsAXEQkRQRX4OmkrIuJZUAW+jvBFRDwLisBP\nSEgAoMAXEfEmKAI/LCwMCQkJCnwRES/8Gvhm9r9mtsbMfjCzEf6sSzNmioh457fAN7PWAP4CoBOA\ntgD6mNk5/qpPM2aKiHjnzyP8FgD+S/IIyVwA8wBc6a/KFPgiIt75M/DXAEg3szpmFgegN4AzTi5k\nZreZWaaZZe7Zs6fMlWmKZBER7/wW+CSzADwLYDaAGQBWAsgtptw4kqkkU+vVq1fm+nSELyLinV9P\n2pIcT7IDyXQAvwNY56+6dNJWRMS7CH/u3Mzqk9xtZk0AXAWgi7/q0hG+iIh3fg18AP82szoAcgAM\nJ7nPXxW53/UqLCwoLi8QEalQfg18kmn+3L+7gimSDx8+XDjVgoiInBA0h8KaT0dExLugC3yduBUR\nKV7QBb6O8EVEiqfAFxEJEUET+LqvrYiId0ET+BrDFxHxLugCX0f4IiLFC5rAj4+PB6DAFxHxJGgC\nPzw8HPHx8Qp8EREPgibwAU2RLCLiTVAFvmbMFBHxLOgCX0f4IiLFU+CLiIQIBb6ISIgIqsDXSVsR\nEc+CKvB10lZExLOgC/yCu16JiEhRQRf4gOuuVyIiUlRQBr7G8UVEThVUgV8wRbLG8UVEThVUga8j\nfBERzxT4IiIhQoEvIhIigirwdZtDERHP/Br4ZnaXmf1gZmvM7H0zi/FnfbrNoYiIZ34LfDM7HcCd\nAFJJtgYQDuB6f9UH6K5XIiLe+HtIJwJArJlFAIgDsN2flemuVyIinvkt8EluA/ACgM0AdgA4QHLW\nyeXM7DYzyzSzzD179pS7Xs2YKSJSPH8O6dQCcDmAZACNANQwsxtPLkdyHMlUkqn16tUrd72aMVNE\npHj+HNLJALCB5B6SOQA+AdDVj/UB0IyZIiKe+DPwNwPobGZxZmYAegDI8mN9ADSkIyLiiT/H8BcD\n+BjAMgCrnbrG+au+Agp8EZHiRfhz5yQfBfCoP+s4mQJfRKR4QXWlLeA6aasxfBGRUwVd4OuuVyIi\nxQvKwAd01ysRkZMFbeBrHF9EpCgFvohIiAi6wNdtDkVEihd0ga8jfBGR4inwRURChAJfRCREKPBF\nREJE0AV+QkICAJ20FRE5WdAFvu56JSJSvKALfEATqImIFEeBLyISIoI28DWGLyJSVFAGvu5rKyJy\nqqAMfA3piIicSoEvIhIiFPgiIiEiaANfd70SESkqKAM/KSkJJHXXKxERN0EZ+JpPR0TkVAp8EZEQ\n4bfAN7MUM1vh9jhoZiP8VZ87Bb6IyKki/LVjkmsBtAMAMwsHsA3AVH/V564g8HW1rYjICZU1pNMD\nwC8kN1VGZQX3tdURvojICZUV+NcDeL+4FWZ2m5llmlnmnj17KqQyDemIiJzK74FvZlEA+gH4qLj1\nJMeRTCWZWq9evQqpU4EvInKqyjjC/zOAZSR3VUJdAHTXKxGR4lRG4A+Ah+EcfwkPD0eNGjV0hC8i\n4sanwDezs8ws2nl+kZndaWY1fdguDsAlAD4pXzNLT1Mki4gU5esR/r8B5JnZ2QDGA0gGMLmkjUge\nIVmHZKWPrWgCNRGRonwN/HySuQCuBPAyybsAnOa/ZpWfAl9EpChfAz/HzAYAGATgC2dZpH+aVDF0\nm0MRkaJ8Dfz/AdAFwFMkN5hZMoCJ/mtW+ekIX0SkKJ+mViD5I4A7AcDMagFIIPmMPxtWXjppKyJS\nlK/f0plrZolmVhvASgDvmNlo/zatfHSELyJSlK9DOkkkDwK4CsA7JDsCyPBfs8pPd70SESnK18CP\nMLPTAFyLEydtq7TExETd9UpExI2vgf8EgJlwzXj5vZmdCWCd/5pVfpoxU0SkKF9P2n4Et8nPSP4K\n4Gp/NaoiaAI1EZGifD1p29jMpprZbjPbZWb/NrPG/m5ceSjwRUSK8nVI5x0AnwNoBOB0ANOcZVWW\n7nolIlKUr4Ffj+Q7JHOdxwQAFTN5vZ/oCF9EpChfA3+vmd1oZuHO40YAv/mzYeWlk7YiIkX5GvhD\n4PpK5k4AOwBcA9d0C1WWjvBFRIryKfBJbibZj2Q9kvVJXgHXRVhVVsFdrxT4IiIu5bnj1d0V1go/\nKLjrlU7aioi4lCfwrcJa4SeaT0dE5ITyBD4rrBV+ohkzRURO8HqlrZkdQvHBbgBi/dKiCqQjfBGR\nE7wGPsmEymqIPzRp0gSLFy8GSZhV+REoERG/Ks+QTpWXkZGBLVu2YO3atYFuiohIwAV14Pfs2RMA\nMGvWrAC3REQk8II68JOTk3HOOedg5syZgW6KiEjABXXgA66j/Llz5yI7OzvQTRERCSi/Br6Z1TSz\nj83sJzPLMrMu/qyvOD179sSRI0ewcOHCyq5aRKRK8fcR/isAZpA8F0BbAFl+ru8UF198MSIiIjSs\nIyIhz2+Bb2aJANIBjAcAksdJ7vdXfZ4kJCSga9euOnErIiHPn0f4ZwLYA+AdM1tuZv80sxonFzKz\n28ws08wy9+zZ45eG9OzZE8uXL8fu3bv9sn8RkerAn4EfAaADgH+QbA/gDwD3n1yI5DiSqSRT69Xz\nzz1VLr30UgDA7Nmz/bJ/EZHqwJ+BvxXAVpKLnZ8/husPQKVr37496tSpo2EdEQlpfgt8kjsBbDGz\nFGdRDwA/+qs+b8LDw5GRkYFZs2aBrPJzvomI+IW/v6VzB4BJZrYKQDsAT/u5Po8uvfRS7Ny5E6tX\nrw5UE0REAsrr5GnlRXIFgFR/1uGrSy65BIBrmoU2bdoEuDUiIpUv6K+0LdC4cWO0bNlS4/giErJC\nJvAB17DO/PnzceTIkUA3RUSk0oVU4Pfs2RPZ2dlYsGBBoJsiIlLpQirw09PTER0drWEdEQlJIRX4\ncXFxSEtL07w6IhKSQirwAdewzg8//IBt27YVWb527VoMHjwYycnJ2L59e4BaJyLiPyEZ+MCJaRZW\nrFiBa6+9Fi1atMD777+PjRs3ashHRIJSyAV+mzZt0KBBA7zzzjvo06cP2rdvj5kzZ+KBBx7A5s2b\nUbt2bZ3UFZGg5NcLr6oiM0PPnj3x3nvvoU6dOnjyyScxfPhw1KxZEwDQrVs3zJ8/P8CtFBGpeCEX\n+AAwatQodO/eHf3790eNGkVnbE5PT8fnn3+OHTt24LTTTgtQC0VEKl7IDekAQNOmTTF48OBTwh4A\n0tLSAEDDOiISdEIy8L1p3749atSoocAXkaCjwD9JZGQkunTponF8EQk6CvxipKenY/Xq1di3b1+g\nmyIiUmEU+MVIT08HSXz33XeBboqISIVR4BejU6dOiIyM1Di+iAQVBX4xYmNj0alTJ43ji0hQUeB7\nkJaWhszMTPzxxx+BboqISIVQ4HuQnp6O3NxcLF68ONBNERGpEAp8D7p27Qoz07COiAQNBb4HSUlJ\naNeunU7cikjQUOB7kZaWhkWLFuH48eOBboqISLkp8L1IT0/H0aNHsWzZsmLXk8SoUaPw6KOP4ocf\nfqjk1omIlI4C34uCidQ8jeOPHz8ejzzyCJ544gm0bt0arVq1wuOPP46srKzKbKaIiE/8GvhmttHM\nVpvZCjPL9Gdd/lC/fn2kpKQUO46flZWFO++8ExkZGdi2bRtee+011K1bF48//jhatmyJNm3aYOLE\niQFotYhI8SrjCP9iku1IplZCXRUuPT0d3377LfLz8wuXHTt2DNdffz3i4+Pxr3/9C40aNcLw4cMx\nb948bN26FWPGjEFYWBgGDx6M5cuXB7D1IiInaEinBGlpadi/fz/WrFlTuOzee+/FqlWrMGHChFNu\nktKoUSPccccd+Oabb1C3bl3ceuutyM3Nrexmi4icwt+BTwCzzGypmd1WXAEzu83MMs0sc8+ePX5u\nTumlp6cDODGO//nnn+O1117DXXfdhd69e3vcrnbt2nj11VexbNkyvPzyy5XSVhERb4yk/3Zu1ojk\ndjOrD2A2gDtIerySKTU1lZmZVW+ov0mTJujcuTNGjx6Ntm3bolmzZli4cCGio6O9bkcSV1xxBWbP\nno3Vq1fjrLPOqqQWi0ioMLOlvg6Z+/UIn+R259/dAKYC6OTP+vwlPT0dCxYswI033ojs7Gy8//77\nJYY94Lph+tixYxEREYGhQ4fCn39cRURK4rfAN7MaZpZQ8BxATwBrvG9VNaWlpWHnzp2YN28exo4d\ni+bNm/u8bePGjfHss8/i66+/xrvvvuvHVoqIeOfPI/wGAL41s5UAlgD4kuQMP9bnNxdddBEAYODA\ngbj55ptLvf3QoUPRrVs33H333di1a1e520MS27Ztw5dffolNmzaVe38iEhr8OoZfWlV1DB8AFixY\ngPPPPx8xMTFl2v6nn35C27ZtceWVV+KDDz4o1ba7du3CokWLsHTpUixduhTLli0r/MORkpKCFStW\nlLldIlK9VZkx/GCSlpZWrlA999xz8be//Q1TpkzBtGnTfN7u008/RdOmTXHllVfi6aefxpYtW9Cr\nVy+MGTMGr7/+OtauXYunn366zO0SkRBCsso8OnbsyGCWnZ3N1q1bs2HDhlyyZEmJ5SdMmMCwsDB2\n7tyZCxcu5B9//HFKmZtuuokRERFcvXq1P5osIlUcgEz6mLE6wq9EUVFRmDx5MqKiotC1a1e88MIL\nRa7gdffKK69g8ODB6NGjB2bPno0uXbogLi7ulHKjR49GzZo1ceuttyIvL89r/d999x0GDhyIe+65\nB2+99Rbmz5+PXbt26dtDIqHC178MlfEI9iP8Ar///juvuuoqAmCvXr24a9euwnX5+fl85JFHCIBX\nX301jx07VuL+Jk6cSAAcM2aMxzJz5sxhbGwsa9asyZiYGMJ1URwBMCkpiV26dOG4ceN8qk9Eqg6U\n4gg/4CHv/giVwCddwf76668zOjqaDRs25Jw5c5iXl8c77riDADhkyBDm5OT4vK9LL72U8fHx3LRp\n0ynrZ8yYwZiYGLZu3Zo7d+5kXl4eN2zYwBkzZvCVV17h7bffznbt2hEAGzVqxNGjR/Pw4cMV3WUR\n8QMFfjWycuVKtmjRgmbGTp06EQBHjhzJ/Pz8Uu1nw4YNjIuL42WXXVZk22nTpjEqKort2rXjnj17\nPG6fn5/PWbNm8eKLLyYA1qlTh0888QR///33MvdNRPxPgV/NHD58mLfeeisB8Kmnnip12BcYPXo0\nAfCDDz4gSU6dOpWRkZFMTU3lb7/95vN+Fi5cyL59+xIA4+PjecMNN3D8+PHcsGFDmdolIv5TmsDX\n9/CrkH379qFWrVpl3j4vLw9dunTBpk2bMGrUKAwfPhypqamYMWMGkpKSSr2/VatWYfTo0ZgxY0bh\n9/6Tk5PRvXt3dO/eHX379kVCQkKZ2ysi5Vea7+Er8IPMypUr0bFjR+Tl5aFbt2748ssvkZiYWK59\nkkRWVha+/vprfPPNN5g7dy7279+PtLQ0zJs3D2ZWQa0XkdJS4Ie4V155BYsWLcI///lPxMfHV/j+\n8/Ly8MILL+D+++/H3LlzceGFF1Z4HSLiGwW++N3Ro0fRrFkzdOjQAdOnTw90c0RClqZWEL+LjY3F\niBEjMGPGDN3GUaSaUOBLmd1+++1ITEzEM888U2LZffv24b333ivxamAR8R8FvpRZUlIShg0bho8/\n/hjr1q3zWC4/Px8DBgzAzTffjFdffbXc9W7fvl3TQouUgQJfymXEiBGIjIzE888/77HMiy++iJkz\nZ6JJkyZ4+OGHyxXWBw4cQOfOnXHeeecV3mdYRHyjwJdyadiwIYYMGYJ3330X27dvP2X94sWL8eCD\nD6J///6FAT1s2DCU9csCI0aMwLZt21CvXj306tULM2fOLHGbr776Cv369cOKFSvKVKdI0PD1Cq3K\neITqlbbV3S+//MKwsDDec889RZbv27ePzZo1Y9OmTblv3z6S5EsvvUQAfP/990tdz2effUYAfOih\nh7hr1y62a9eOkZGR/Pe//11s+T/++IPDhg0jAIaFhTEuLo4ffvhh6TsoUoVBUytIZRs4cCDj4+ML\n597Jz89n//79GR4ezkWLFhWWy83N5fnnn8/69euXarqHPXv2sEGDBmzbti2zs7NJuv6gdOnSheHh\n4XzvvfeKlP/++++ZkpJCALznnnu4adMmdu3alQD48MMPMy8vrwJ6XblycnKKvSeChDYFvlS6VatW\nEQCfeOIJkuS4ceMIgM8888wpZVesWMHw8HAOGTLEp33n5+fzmmuuYWRkJFeuXFlk3aFDh9i9e3ea\nGf/xj38wNzeXTz75JCMiIti4cWN+/fXXhWWPHTvGIUOGEAAvv/xyHjx4sBw99k1OTg6/+OILHj16\ntNz7uuWWW9i0aVOFvhShwJeA6NOnD+vUqcMlS5YwJiaGl1xyiccj6fvvv58A+M0335S430mTJhEA\n//73vxe7/ujRo+zTpw8BFB7VX3/99cXO9Jmfn88xY8YwPDycrVq14vr160vVxw8++ICvv/66z+VH\njRpFADz//PO5ZcuWUtXlbvPmzYyIiCicYE+kgAJfAuLbb78lAMbGxrJBgwbcuXOnx7JHjhzhWWed\nxbPPPptHjhzxWG7btm2sWbMmO3fuzNzcXI/ljh8/zoEDBzIpKYmTJk0qsa1z5sxh7dq1WatWLc6Z\nM6fE8iT52muvFd405quvviqxfFZWFqOioti5c2fGx8ezfv36nDdvnk91nWzkyJEMDw/nBRdcwISE\nBO7evbvEbX788Ue2aNGCgwYN4jfffFMlhrHy8vI4aNAgvvXWW4FuStBQ4EvApKWlEQBnzpxZYtk5\nc+YQAB988MFi1+fn57NXr16MjY3lzz//7FP9x48f97mt69evZ6tWrRgeHl7iUfvLL79MAOzXr1/h\nfYn37t3rsXxeXh7T0tJYq1Yt7ty5kz/++CObN2/OiIgIjhkzplRTYO/fv58JCQkcMGAAs7KyGB4e\nzjvuuMPrNjk5OUxNTWViYiITExMJgE2bNuXf/vY3rlu3zue6K9qHH35IAIyIiOB///vfgLUjmCjw\nJWC2bNnCWbNm+Vx+8ODBjIiI4LXXXsvhw4fzscce49ixYzllyhQ+9thjBMBXX33Vb+09cOAAe/fu\nTQAcPnx4sXcZe/HFFwmAV111FbOzs7l8+XJGRkayf//+HoP7zTffJACOHz++cNn+/fsL7zNw8803\ne/1k4+65554jAC5dupQkOXToUEZERHgN7oKhpI8++ohHjhzh5MmTeemllzIsLIwAeMEFF/j0R7ki\n5eTkMCUlhS1atGDTpk2ZnJzM/fv3V2obglGVCnwA4QCWA/iipLIK/NDz22+/sV+/fmzevDlr1apV\n5F67ANijRw+/D0Xk5uZy5MiRBMCMjIwiY//PPvssAbB///5FPj08/fTTBFDs8NG2bduYmJjI7t27\nn/IHIS8vj48//jgBsEOHDty6davXtmVnZ/P0009n9+7dC5ft2LGDNWrUYP/+/YvdZvny5YyIiOCA\nAQNOWbd161Y+88wzPOusswiAt99+u0+3s9y/f3+5PxmMHz+eADh16lR+9913DA8P5/XXX1/mG/6I\nS1UL/LsBTFbgiy+OHz/OHTt2cNWqVZw3b16l3lT97bffZmRkJM855xz+9NNPfOqppwpPAJ985J+b\nm8uuXbuyZs2ap5yMveqqqxgTE+M1ID///HPGx8czNTXV6zd43n33XQLg9OnTiyx/9NFHCeCUYZFj\nx47xvPPOY8OGDb1+7fXo0aO8++67aWY855xzinx11t327dt53333MSEhgQDYtWtXTpo0qfCrsb46\nevQozzjjDP7pT38qDPgnn3ySAPjOO++Ual9V2e7duzl8+HCOHz/e53tSl1eVCXwAjQF8DaC7Al+q\ng/nz57Nu3bqMjY0lAN54440e/+OuX7+eNWrUYEZGRuGnkE8++cTj11FP9umnnxIA//KXvxS7Pj8/\nn+eddx5bt259ylHwoUOH2KBBA6alpRVZ98ADDxAAv/jiC5/6+5///IdNmzZlWFgYH3roocIgX7du\nHYcOHcro6GiGhYXxuuuu47PPPsuzzz6bANigQQM+/PDDPn/zqOCCO/evyebm5vKiiy5ijRo1+NNP\nP/m0H3/Zt2+f13s++2LWrFls2LBh4afT5s2bc8qUKX7/hFqVAv9jAB0BXOQp8AHcBiATQGaTJk38\n+bqI+OTXX39l586dOXToUK/fDCLJN954gwA4ZswY7tu3j6eddhrbtm3r88njgoB2H+svMGPGDALg\nhAkTvNb96aefknTdizgsLIy33HKLT3UXOHDgAAcPHkwAbN++Pa+77jqGhYUxKiqKt912W5FPKnl5\neZw+fTr79OlDM2N4eDivvfZar2F58OBB1qtXjz169Dhl3datW1m7dm22b9++2E9z+fn5XLhwoc9/\nwErj0KFDnDx5Mvv27cvIyEjWqlWLS5YsKfV+jh07Vjgk2LJlSy5fvpyffvopW7VqVfiafvXVV34b\nuqoSgQ+gD4DXneceA9/9oSNLluevAAANL0lEQVR8qW7y8/PZu3dvxsTEsG/fvgwLC+P333/v8/a5\nubnMyMhgdHR04UnZAhkZGWzUqJHH4ZOCk6ApKSk8cOAAzznnHDZp0oQHDhwoU1+mTp3KevXqMT4+\nnvfeey+3b9/utfyvv/7K++67jzExMUxJSeHGjRuLLffEE08QABcvXlzs+oIpM+666y6Srtd02bJl\nvO+++9i0adPCI+a5c+eWqV/ujh49yqlTp/K6665jXFwcAbBx48a86667mJyczISEBC5YsMDn/WVl\nZbF9+/YEwGHDhhW5KC43N5fvvfcezzzzTAJgt27duHz58nL34WRVJfD/DmArgI0AdgI4AmCit20U\n+FIdbd++nXXq1CEAjhw5stTb7969m2eccQabNWtW+FXPZcuW+TQ0VDAs1LJly1OGTMri2LFjpb6S\nd8GCBaxZsyYbNWrEVatWFVm3d+9eJiYm8oorrvC6j7/+9a8EwKFDh7J58+aFX93s3bs3J0yYwGbN\nmrFly5Y+f3LKzc3lunXrOHXqVI4aNYrXXXcdW7VqVXjxWt26dTls2DDOnz+/cMhly5YtTElJYVxc\nHGfPnu11/3l5eXzzzTcZGxvLOnXq8LPPPvNYNjs7m//4xz/YoEEDnnHGGRV+pXSVCPwilegIX4Lc\njBkz2L9/f5++8VKcxYsXMyoqir169WJubi5vuOEGxsfHF04650l+fj67detGACV+N9+fVq9ezdNP\nP51JSUlFLi679957aWZcs2aN1+2PHj3Ktm3bMiwsjN27d+e4ceOKXOcwbdo0AuBzzz1XYlt+/vln\nNmrUqMi3vZKTk9m3b18+8MADnD59usc/HDt37uR5553H6OhoTps27ZT1OTk5nDRpElu3bl34ra5t\n27aV2CbSdX4IAB955BGfyvtKgS9SDRWMyd92220MDw8vHOIoyY8//sg777yzzH9sKsqmTZt47rnn\nMjo6mp988gm3bdvGmJgY3nTTTT5tf/DgQa9XEPfr149xcXHcvHmz1320bNmStWvX5j//+U8uXryY\nhw4dKlU/fvvtN6ampjIiIqJwdtVjx45x3LhxhV9nbdmyJSdOnFjqE7IDBgxgdHQ0f/3111Jt502V\nC3xfHwp8CWX5+fkcNGgQATA8PJybNm0KdJNKbe/evezcuTPDwsLYsWNHRkZGVli4bdiwgbGxsbz6\n6quLXZ+fn8+rrrqKYWFhJQ7JlGT//v3s1q0bw8LCOHz4cJ5++ukEwI4dO/KTTz4p8zdvtmzZwri4\nOF555ZXlap87Bb5INXXkyBFeeOGFvPPOOwPdlDI7fPgwL7vsssILuypSwQVvxc1lVHDdxAsvvFAh\ndR0+fJgZGRkEwLS0NM6YMaNCvmlT0M7SXJHuTWkC31zlq4bU1FRmZmYGuhkiAVXwf9LMAtySssvJ\nycGHH36Ifv36ISEhocL2e/z4cbRp0wa5ublYs2YNYmJiALjuatanTx8MGDAAEydOrLDXLicnB+vX\nr0eLFi0qZH8AcOzYMbRu3RpRUVFYuXIlIiMjy7U/M1tKMtWXsrrFoUgVY2bVOuwBIDIyEjfccEOF\nhj0AREVFYezYsfjll1/w7LPPAgDWr1+PgQMHok2bNnjrrbcq9LWLjIys0LAHgJiYGLz00kvIysrC\n2LFjK3TfJdERvohUOwMGDMDUqVOxePFi3HDDDdixYwcyMzORnJwc6Kb5hCR69+6NhQsXYt26dahf\nv36Z96UjfBEJai+++CKioqLQuXNnZGVlYcqUKdUm7AHXp7iXX34ZR44cwYMPPlhp9SrwRaTaadSo\nEUaNGoVjx47hueeeQ0ZGRqCbVGopKSkYMWIE3n77bXz//feVUqeGdESkWiKJn3/+Gc2bN6+25zwO\nHjyI5s2bIzk5Gd999x3Cwkp/DK4hHREJemaGlJSUahv2AJCYmIjnn38eHTp0QHZ2tt/r0xG+iEg1\npiN8ERE5hQJfRCREKPBFREKEAl9EJEQo8EVEQoQCX0QkRCjwRURChAJfRCREVKkLr8xsD4BNJRSr\nC2BvJTSnqlG/Q4v6HVrK0++mJOv5UrBKBb4vzCzT16vKgon6HVrU79BSWf3WkI6ISIhQ4IuIhIjq\nGPjjAt2AAFG/Q4v6HVoqpd/VbgxfRETKpjoe4YuISBko8EVEQkS1CXwz62Vma81svZndH+j2lIWZ\nvW1mu81sjduy2mY228zWOf/WcpabmY1x+rvKzDq4bTPIKb/OzAa5Le9oZqudbcZYFbkVkJmdYWb/\nMbMsM/vBzP7XWR7UfTezGDNbYmYrnX4/7ixPNrPFTh+mmFmUszza+Xm9s76Z274ecJavNbNL3ZZX\n2f8XZhZuZsvN7Avn56Dvt5ltdN6HK8ws01lWdd7nJKv8A0A4gF8AnAkgCsBKAC0D3a4y9CMdQAcA\na9yWPQfgfuf5/QCedZ73BjAdgAHoDGCxs7w2gF+df2s5z2s565YA6OJsMx3AnwPdZ6ddpwHo4DxP\nAPAzgJbB3nenLfHO80gAi53+fAjgemf5GwCGOc9vB/CG8/x6AFOc5y2d93w0gGTn/0J4Vf9/AeBu\nAJMBfOH8HPT9BrARQN2TllWZ93nAXyAfX8QuAGa6/fwAgAcC3a4y9qUZigb+WgCnOc9PA7DWef4m\ngAEnlwMwAMCbbsvfdJadBuAnt+VFylWlB4DPAFwSSn0HEAdgGYA/wXVFZYSzvPC9DWAmgC7O8win\nnJ38fi8oV5X/XwBoDOBrAN0BfOH0IxT6vRGnBn6VeZ9XlyGd0wFscft5q7MsGDQguQMAnH/rO8s9\n9dnb8q3FLK9SnI/r7eE62g36vjvDGisA7AYwG64j0/0kc50i7m0t7J+z/gCAOij961EVvAzgPgD5\nzs91EBr9JoBZZrbUzG5zllWZ93lEaQoHUHHjVMH+fVJPfS7t8irDzOIB/BvACJIHvQw/Bk3fSeYB\naGdmNQFMBdCiuGLOv6XtX3EHbAHvt5n1AbCb5FIzu6hgcTFFg6rfjgtIbjez+gBmm9lPXspW+vu8\nuhzhbwVwhtvPjQFsD1BbKtouMzsNAJx/dzvLPfXZ2/LGxSyvEswsEq6wn0TyE2dxSPQdAEjuBzAX\nrrHammZWcLDl3tbC/jnrkwD8jtK/HoF2AYB+ZrYRwAdwDeu8jODvN0hud/7dDdcf+E6oSu/zQI95\n+TguFgHXiYtknDhJ0yrQ7SpjX5qh6Bj+8yh6Quc55/llKHpCZ4mzvDaADXCdzKnlPK/trPveKVtw\nQqd3oPvrtMsA/AvAyyctD+q+A6gHoKbzPBbAAgB9AHyEoicvb3eeD0fRk5cfOs9boejJy1/hOnFZ\n5f9fALgIJ07aBnW/AdQAkOD2fCGAXlXpfR7wN0QpXszecH274xcADwW6PWXsw/sAdgDIgeuv9S1w\njVV+DWCd82/BL9YAjHX6uxpAqtt+hgBY7zz+x215KoA1zjavwbmSOtAPAN3g+ui5CsAK59E72PsO\noA2A5U6/1wB4xFl+JlzftljvhGC0szzG+Xm9s/5Mt3095PRtLdy+mVHV/1+gaOAHdb+d/q10Hj8U\ntKsqvc81tYKISIioLmP4IiJSTgp8EZEQocAXEQkRCnwRkRChwBcRCREKfKnWzKyBmU02s1+dy9kX\nmdmVAWrLRWbW1e3n/2dmNweiLSLFqS5TK4icwpka9lMA75Ic6CxrCqCfH+uM4In5YE52EYDDcF1w\nA5Jv+KsdImWh7+FLtWVmPeC6mOnCYtaFA3gGrhCOBjCW5JvO3C6PwTUjY2sASwHcSJJm1hHAaADx\nzvrBJHeY2Vy4QvwCAJ/DdcHPw3Bd5fkbgBvgupL2vwDyAOwBcAeAHgAOk3zBzNrBdXVpHFwXzQwh\nuc/Z92IAFwOoCeAWkgsq7lUSOUFDOlKdtYJryuHi3ALgAMnzAZwP4C9mluysaw9gBFzzrZ8J4AJn\nrp9XAVxDsiOAtwE85ba/miQvJPkigG8BdCbZHq65Yu4juRGuQH+JZLtiQvtfAP6PZBu4rqp81G1d\nBMlOTpsehYifaEhHgoaZjYVrGofjADYBaGNm1zirkwCc46xbQnKrs80KuOY32g/XEf9sZxbPcLim\nwSgwxe15YwBTnImwouCa68Rbu5Lg+oMxz1n0LlxTCRQomExuqdMWEb9Q4Et19gOAqwt+IDnczOoC\nyASwGcAdJGe6b+AM6WS7LcqD6/+BAfiBZBcPdf3h9vxVAKNJfu42RFQeBe0paIuIX2hIR6qzbwDE\nmNkwt2Vxzr8zAQxzhmpgZs3NrIaXfa0FUM/MujjlI82slYeySQC2Oc8HuS0/BNctHIsgeQDAPjNL\ncxbdBGDeyeVE/E1HE1JtOSdarwDwkpndB9fJ0j8A/B9cQybNACxzvs2zB8AVXvZ13Bn+GeMMwUTA\nNYf7D8UUfwzAR2a2Da4TtQXnBqYB+NjMLofrpK27QQDeMLM4uKb2/Z/S91ikfPQtHRGREKEhHRGR\nEKHAFxEJEQp8EZEQocAXEQkRCnwRkRChwBcRCREKfBGREPH/AWIvEVVzvee3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21aab2fc470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_x_vec, loss_vec, 'k-')\n",
    "plt.title('Training Loss per Generation')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 질문!\n",
    "왜 similarity에 마이너스를 붙여서 하는지 모르겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
